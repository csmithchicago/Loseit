{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Past Loseit Challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import praw\n",
    "import datetime as dt\n",
    "import markdown\n",
    "from lxml import etree\n",
    "import lxml\n",
    "import gspread\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data/raw_data/'):\n",
    "    os.makedirs('./data/raw_data/')\n",
    "if not os.path.exists('./figures/'):\n",
    "    os.makedirs('./figures/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit('loseit_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loseit_sub = reddit.subreddit('loseit')\n",
    "challenge_posts = loseit_sub.search(\"loseit challenge tracker\", limit=1000)\n",
    "topics_dict = { \"title\":[], \"score\":[], \"id\":[], \"url\":[], \"comms_num\": [],\n",
    "                \"created\": [], \"body\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for submission in challenge_posts:\n",
    "    topics_dict[\"title\"].append(submission.title)\n",
    "    topics_dict[\"score\"].append(submission.score)\n",
    "    topics_dict[\"id\"].append(submission.id)\n",
    "    topics_dict[\"url\"].append(submission.url)\n",
    "    topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "    topics_dict[\"created\"].append(submission.created)\n",
    "    topics_dict[\"body\"].append(submission.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_data = pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "_timestamp = topics_data[\"created\"].apply(get_date)\n",
    "topics_data = topics_data.assign(timestamp = _timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_data.to_csv('loseit_search_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have searched through old loseit posts, we need to find the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for body in topics_dict['body']:\n",
    "    try:\n",
    "        doc = etree.fromstring(markdown.markdown(re.sub('[\\\\n]', '', body)))\n",
    "        for link in doc.xpath('//a'):\n",
    "            web_url = link.get('href')\n",
    "            if bool(re.search('spreadsheet',web_url)):\n",
    "                links.append(web_url)\n",
    "    except etree.XMLSyntaxError:\n",
    "        print('incorrect code used in body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_spreadsheets = list(set(links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have the urls, we need to use the google API to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use creds to create a client to interact with the Google Drive API\n",
    "names = []\n",
    "for spreadsheet_link in unique_spreadsheets:\n",
    "    scope = ['https://spreadsheets.google.com/feeds']\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_name('loseit-sheets-6012c29a1f40.json', scope)\n",
    "    gc = gspread.authorize(creds)\n",
    "    sht = gc.open_by_url(spreadsheet_link)\n",
    "    if bool(re.search('nter', sht.title)) == False and bool(re.search('/r/', sht.title)) == False and bool(re.search('Calculator', sht.title)) == False:\n",
    "        sheet_name = re.sub('_\\(responses\\)' ,'', re.sub(',', '', re.sub('\\]','', re.sub('\\[','', re.sub(' ', '_', re.sub('  ', '_', re.sub('-', '', sht.title.lower())))))))\n",
    "        if sheet_name not in names:\n",
    "            print(f'sheet name: {sheet_name}, link: {spreadsheet_link}')\n",
    "            names.append(sheet_name)\n",
    "            try: \n",
    "                data_sheet = sht.worksheet('Tracker')\n",
    "                data_vals = data_sheet.get_all_values()\n",
    "                data_df = pd.DataFrame(data_vals[1:], columns=data_vals[0])\n",
    "                data_df.to_csv('./data/raw_data/' + sheet_name + '.csv')\n",
    "            except gspread.WorksheetNotFound:\n",
    "                try:\n",
    "                    data_sheet = sht.worksheet('Master Spreadsheet')\n",
    "                    data_vals = data_sheet.get_all_values()\n",
    "                    data_df = pd.DataFrame(data_vals[1:], columns=data_vals[0])\n",
    "                    data_df.to_csv('./data/raw_data' + sheet_name + '.csv')\n",
    "                except gspread.WorksheetNotFound:\n",
    "                    print('')#sheet_name)\n",
    "            else:\n",
    "                print('')#sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the data is downloaded, it is time to load in the data and clean it down to the catagories that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_col = {f'W{x}':f'Week {x}' for x in range(0, 11)}\n",
    "new_names = {'W0 (SW)': 'Week 0', 'Sex': 'Gender', 'Male, Female, Other': 'Gender',\n",
    "             'TEAM': 'Team', 'Teams': 'Team', 'Challenge GW': 'Challenge Goal Weight',\n",
    "             'Challenge SW': 'Week 0', 'Signup weight': 'Week 0', \n",
    "             'MyFitnessPal Username/Link': 'MFP'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "p = Path('./data/raw_data/')\n",
    "for challenge in p.rglob('*.csv'):\n",
    "    test_df = pd.read_csv(challenge, index_col=0)\n",
    "    test_df.rename(index=str, columns=new_names, inplace=True)\n",
    "    test_df.columns = test_df.columns.str.strip().str.replace('?', '').str.replace(':','')\n",
    "    # timestamp\n",
    "    if 'Timestamp' not in test_df:\n",
    "        test_df['Timestamp'] = np.NaN\n",
    "    # Age\n",
    "    test_df['Age'] = test_df[test_df.filter(regex=re.compile('Age', re.IGNORECASE)).columns[0]]\n",
    "    # Gender\n",
    "    if 'Gender' not in test_df:\n",
    "        test_df['Gender'] = 'Unknown'\n",
    "    # Ignore KGS\n",
    "    test_df.drop(test_df.filter(regex=re.compile('kgs', re.IGNORECASE)).columns, axis=1, inplace=True)\n",
    "    # Just Starting BMI\n",
    "    test_df.drop(test_df.filter(regex=re.compile('BMI', re.IGNORECASE)).columns[1:], axis=1, inplace=True)\n",
    "    # Username\n",
    "    test_df.columns = test_df.columns.str.replace(test_df.filter(like='name').columns[0], 'Username')\n",
    "    # Weigh-in Data\n",
    "    test_df.rename(index=str, columns=weeks_col, inplace=True)\n",
    "    test_df['Week 0'] = test_df[test_df.filter(regex=re.compile(\"current weight\", re.IGNORECASE)).columns[0]]\n",
    "    # Height\n",
    "    test_df['Height'] = test_df[test_df.filter(regex=re.compile(\"Height\", re.IGNORECASE)).columns[0]]    \n",
    "    # Highest Weight\n",
    "    if len(test_df.filter(regex=re.compile('Highest', re.IGNORECASE)).columns):\n",
    "        test_df['Highest Weight'] = test_df[test_df.filter(regex=re.compile('Highest', re.IGNORECASE)).columns[0]]\n",
    "    else:\n",
    "        test_df['Highest Weight'] = np.NaN\n",
    "    # Has NSV\n",
    "    test_df['Has NSV'] = test_df[test_df.filter(regex=re.compile(\"NSV\", re.IGNORECASE)).columns[0]].notnull().astype('int')\n",
    "    # Goal Weight\n",
    "    test_df['Challenge Goal Weight'] = test_df[test_df.filter(regex=re.compile(\"Goal Weight\", re.IGNORECASE)).columns[0]]\n",
    "\n",
    "    # Has a food tracker\n",
    "    if len(test_df.filter(regex=re.compile('MyFitnessPal', re.IGNORECASE)).columns):\n",
    "        test_df['MFP'] = test_df[test_df.filter(regex=re.compile('MyFitnessPal', re.IGNORECASE)).columns].notnull().astype('int')    \n",
    "    test_df['Has MFP'] = test_df[test_df.filter(regex=re.compile(\"MFP\", re.IGNORECASE)).columns[0]].notnull().astype('int')\n",
    "    if len(test_df.filter(regex=re.compile(\"Loseit\", re.IGNORECASE)).columns):\n",
    "        test_df['Has Loseit'] = test_df[test_df.filter(regex=re.compile(\"Loseit\", re.IGNORECASE)).columns].notnull().astype('int')\n",
    "    else:\n",
    "        test_df['Has Loseit'] = 0\n",
    "    test_df['Has Food Tracker'] = test_df['Has MFP'] + test_df['Has Loseit']\n",
    "    test_df[test_df['Has Food Tracker'] > 0] = 1\n",
    "    \n",
    "    # fitness tracker\n",
    "    if len(test_df.filter(regex=re.compile('Fitbit', re.IGNORECASE)).columns):\n",
    "        test_df['Has Activity Tracker'] = test_df[test_df.filter(regex=re.compile('Fitbit', re.IGNORECASE)).columns].notnull().astype('int')\n",
    "    elif len(test_df.filter(regex=re.compile('Fitness tracker', re.IGNORECASE)).columns):\n",
    "        test_df['Has Activity Tracker'] = test_df[test_df.filter(regex=re.compile('Fitness Tracker', re.IGNORECASE)).columns].notnull().astype('int')\n",
    "    elif len(test_df.filter(regex=re.compile('Garmin', re.IGNORECASE)).columns):\n",
    "        test_df['Has Activity Tracker'] = test_df[test_df.filter(regex=re.compile('Garmin', re.IGNORECASE)).columns].notnull().astype('int')\n",
    "    elif len(test_df.filter(regex=re.compile('Strava', re.IGNORECASE)).columns):\n",
    "        test_df['Has Activity Tracker'] = test_df[test_df.filter(regex=re.compile('Strava', re.IGNORECASE)).columns].notnull().astype('int')\n",
    "\n",
    "    # clean up any possible duplicates\n",
    "    test_df = test_df.loc[:,~test_df.columns.duplicated()]\n",
    "\n",
    "    # Create the final Data Frame\n",
    "    col_weeks = test_df.filter(regex=re.compile('Week', re.IGNORECASE)).columns.values\n",
    "    col_names = ['Timestamp', 'Username', 'Team', 'Age', 'Gender', 'Height', 'Highest Weight',\n",
    "                 'Challenge Goal Weight', 'Starting BMI', 'Has NSV', 'Has Food Tracker', \n",
    "                 'Has Activity Tracker']\n",
    "    data_cols = col_names + list(col_weeks)\n",
    "    data_df = test_df[data_cols]\n",
    "    data_df.to_csv('./data/Cleaned_' + challenge.name)\n",
    "    df_list.append((challenge.stem, data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the data contains only what we are interested in learning, we need to fill in any missing values before we combine all of the challenges together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenge Name: new_challenge_new_year_new_goals_2018_edition\n",
      "\n",
      "['Timestamp' 'Username' 'Team' 'Age' 'Gender' 'Height' 'Highest Weight'\n",
      " 'Challenge Goal Weight' 'Starting BMI' 'Has NSV' 'Has Food Tracker'\n",
      " 'Has Activity Tracker' 'Week 0' 'Week 1' 'Week 2' 'Week 3' 'Week 4'\n",
      " 'Week 5' 'Week 6' 'Week 7']\n"
     ]
    }
   ],
   "source": [
    "print(f'Challenge Name: {df_list[3][0]}\\n')\n",
    "print(df_list[3][1].columns.values)\n",
    "df = df_list[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Username', 'Challenge Goal Weight', df.columns.values[-1]])\n",
    "df.loc[~df['Gender'].isin(['Female', 'Male', 'Unknown']), 'Gender'] = 'Other'\n",
    "df.loc[pd.isnull(df['Highest Weight']), 'Highest Weight'] = df['Week 0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp                873\n",
       "Username                 873\n",
       "Team                     873\n",
       "Age                      873\n",
       "Gender                   873\n",
       "Height                   873\n",
       "Highest Weight           873\n",
       "Challenge Goal Weight    873\n",
       "Starting BMI             873\n",
       "Has NSV                  873\n",
       "Has Food Tracker         873\n",
       "Has Activity Tracker     873\n",
       "Week 0                   873\n",
       "Week 1                   864\n",
       "Week 2                   861\n",
       "Week 3                   861\n",
       "Week 4                   857\n",
       "Week 5                   841\n",
       "Week 6                   826\n",
       "Week 7                   873\n",
       "dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we want to fill in any other missing info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('./data/')\n",
    "for challenge in p.rglob('Cleaned*.csv'):\n",
    "    df = pd.read_csv(challenge, index_col=0)\n",
    "    print(challenge.stem, df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Height(in inches) True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Username', 'Team', 'Age', 'Gender',\n",
       "       'Current Weight(in pounds/lbs)', 'Challenge Goal Weight',\n",
       "       'Your Height(in inches)', 'What is your current weight',\n",
       "       'Challenge LBS Lost', 'LBS to Goal', 'Signup weight', 'Week 1',\n",
       "       'Week 2', 'Week 3', 'Week 4', 'Week 5', 'Week 6', 'Highest Weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[(test_df.shape[1] - 2) <= test_df.count(axis=1)]#.fillna(axis=1, method='ffill')\n",
    "lb = test_df.filter(regex=re.compile(\"Height\", re.IGNORECASE)).columns[0]\n",
    "print(lb, lb in test_df)\n",
    "test_df.columns.str.replace(test_df.columns.sort_values()[-1], 'Height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                          70\n",
       "2                          69\n",
       "4                          63\n",
       "5                          61\n",
       "6                          78\n",
       "7                          59\n",
       "8                          59\n",
       "10                         63\n",
       "11                         65\n",
       "12                         71\n",
       "13                         72\n",
       "14                         65\n",
       "15                         70\n",
       "16                         66\n",
       "17                         72\n",
       "18                         62\n",
       "19                         62\n",
       "21                         69\n",
       "22                         73\n",
       "23                         66\n",
       "24                         64\n",
       "25                         67\n",
       "27                         71\n",
       "28                         66\n",
       "29                         72\n",
       "30                         64\n",
       "32                         61\n",
       "33                         69\n",
       "35                         63\n",
       "36                         74\n",
       "                ...          \n",
       "911                        66\n",
       "914                        62\n",
       "915                        65\n",
       "917                        78\n",
       "918                        67\n",
       "925                        66\n",
       "927                        70\n",
       "929                      82.6\n",
       "930                        61\n",
       "931                        64\n",
       "932                      77.9\n",
       "934                      65.5\n",
       "935                        71\n",
       "936                        65\n",
       "937                        62\n",
       "939                        65\n",
       "943                        67\n",
       "946                        64\n",
       "947                      64.5\n",
       "950                        67\n",
       "951                        68\n",
       "953                        64\n",
       "954                        64\n",
       "955                        68\n",
       "958                        64\n",
       "959                        73\n",
       "963                      66.5\n",
       "967                      67.7\n",
       "969                        72\n",
       "971    Your Height(in inches)\n",
       "Name: Your Height(in inches), Length: 585, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df.columns.sort_values()[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Gender', kind=\"count\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = df[df['Gender']!='Male']\n",
    "o_df = f_df[f_df.Gender != 'Female']\n",
    "o_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Gender', kind=\"count\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1)\n",
    "ax = sns.distplot(test_df['Week 0'],label='starting weight')\n",
    "ax = sns.distplot(test_df['Week 6'], label='final week')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
